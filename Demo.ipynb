{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Hume-like gibberish\n",
    "\n",
    "This document is a demo for my LSTM implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "from training import train\n",
    "from data_handling import DataLoader\n",
    "from model import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" 0123456789!?,.:;'()[]-$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precomputing data tensors...\n",
      "20.00%\n",
      "39.99%\n",
      "59.99%\n",
      "79.99%\n",
      "99.98%\n",
      "100%: done\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(\"hume.txt\", \n",
    "                         all_letters=all_letters, \n",
    "                         seq_length=500, \n",
    "                         device=device, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM(n_input=data_loader.n_letters, \n",
    "           n_hidden=512, \n",
    "           n_output=data_loader.n_letters, \n",
    "           n_layers=3,\n",
    "           dropout=0.1, \n",
    "           grad_clipping=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1m 50s (200 6.67%) loss: 0.00013\n",
      "  3m 39s (400 13.33%) loss: 0.00010\n",
      "  5m 28s (600 20.00%) loss: 0.00008\n",
      "  7m 20s (800 26.67%) loss: 0.00008\n",
      "  9m 11s (1000 33.33%) loss: 0.00007\n"
     ]
    }
   ],
   "source": [
    "training_params = {\n",
    "    'number of iterations':3000,\n",
    "    'batch size':128,\n",
    "    'subsequence length':100,\n",
    "    'learning rate':0.0005\n",
    "}\n",
    "\n",
    "output_params = {\n",
    "    'plot every':50,\n",
    "    'print every':200\n",
    "}\n",
    "\n",
    "iters, losses = train(rnn, data_loader, training_params, output_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing output\n",
    "\n",
    "Here, we can finally sample from the learned distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample_length = 2000\n",
    "\n",
    "def sample(starting_with=\"\", temperature=1):\n",
    "    verse = starting_with\n",
    "    with torch.no_grad():\n",
    "        rnn.eval()\n",
    "        letter = \"$\" + starting_with\n",
    "        state = rnn.init_state(data_loader.seq2tensor(letter, truncate=False).unsqueeze(1).to(device))\n",
    "        for i in range(max_sample_length):\n",
    "            input_tensor = data_loader.seq2tensor(letter, truncate=False).unsqueeze(1).to(device)\n",
    "            output, state = rnn.sample(input_tensor, state, temperature)\n",
    "            probs = np.exp(output[-1].squeeze().cpu().numpy())\n",
    "            letter = np.random.choice(list(data_loader.all_letters), p=probs)\n",
    "            if letter == \"$\":\n",
    "                return verse\n",
    "            verse += letter\n",
    "    return verse\n",
    "\n",
    "for i in range(10):\n",
    "    print(sample(\"\", temperature=0.9) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
